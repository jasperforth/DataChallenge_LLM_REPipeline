{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Append the submodules path to the local libs directory\n",
    "repo_dir = Path().resolve()\n",
    "sys.path.append(str(repo_dir / 'libs'))\n",
    "\n",
    "# Ensure the symlink exists (assuming setup_symlink.py has been executed)\n",
    "symlink_path = repo_dir / 'libs' / 'NLP_on_multilingual_coin_datasets'\n",
    "if not symlink_path.exists():\n",
    "    print(f\"Error: Symlink {symlink_path} does not exist. Run setup_symlink.py first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Import the custom modules after ensuring symlink is in place\n",
    "from NLP_on_multilingual_coin_datasets.cnt.io import Database_Connection\n",
    "from modules.loading_preprocessed_designs import PreprocessingConfig\n",
    "\n",
    "# Set up pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "prep_cfg = PreprocessingConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "database = prep_cfg.database\n",
    "\n",
    "connection_string = f\"mysql+mysqlconnector://{db_user}:{db_password}@{db_host}:{db_port}/{database}\"\n",
    "dc = Database_Connection(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine\n\u001b[0;32m----> 3\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection established:\u001b[39m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_challenge_git/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py:281\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    275\u001b[0m         _warn_with_version(\n\u001b[1;32m    276\u001b[0m             messages[m],\n\u001b[1;32m    277\u001b[0m             versions[m],\n\u001b[1;32m    278\u001b[0m             version_warnings[m],\n\u001b[1;32m    279\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    280\u001b[0m         )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data_challenge_git/lib/python3.8/site-packages/sqlalchemy/engine/create.py:599\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    598\u001b[0m             dbapi_args[k] \u001b[38;5;241m=\u001b[39m pop_kwarg(k)\n\u001b[0;32m--> 599\u001b[0m     dbapi \u001b[38;5;241m=\u001b[39m \u001b[43mdbapi_meth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdbapi_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m dialect_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dbapi\n\u001b[1;32m    603\u001b[0m dialect_args\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_linting\u001b[39m\u001b[38;5;124m\"\u001b[39m, compiler\u001b[38;5;241m.\u001b[39mNO_LINTING)\n",
      "File \u001b[0;32m~/miniconda3/envs/data_challenge_git/lib/python3.8/site-packages/sqlalchemy/dialects/mysql/mysqlconnector.py:83\u001b[0m, in \u001b[0;36mMySQLDialect_mysqlconnector.import_dbapi\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_dbapi\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmysql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m connector\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connector\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "connection = engine.connect()\n",
    "print(\"Connection established:\", connection)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query failed.\n",
      "Database connection type: <class 'str'>\n",
      "No data returned from the query.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df_RE_groundtruth\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# sort by design id ascending\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df_RE_groundtruth \u001b[38;5;241m=\u001b[39m \u001b[43mdf_RE_groundtruth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesign_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     25\u001b[0m df_RE_groundtruth\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "RE_query = \"\"\"select design_id, \n",
    "(select design_en_changed from nlp_training_designs as nlp where re.design_id=nlp.id) as design_en,\n",
    "(select name_en from nlp_list_entities as ner where ner.id=re.subject) as s, \n",
    "(select class from nlp_list_entities as ner where ner.id=re.subject) as subject_class, \n",
    "(select name_en from nlp_list_entities as ner where ner.id=re.predicate) as p, \n",
    "(select name_en from nlp_list_entities as ner where ner.id=re.object) as o, \n",
    "(select class from nlp_list_entities as ner where ner.id=re.object) as object_class\n",
    "from nlp_relation_extraction_en_v2 as re;\n",
    "\"\"\"\n",
    "\n",
    "df_RE_groundtruth= dc.create_own_query(RE_query)\n",
    "\n",
    "print(\"Database connection type:\", type(dc.mysql_connection))\n",
    "\n",
    "\n",
    "if df_RE_groundtruth is None or df_RE_groundtruth.empty:\n",
    "    print(\"No data returned from the query.\")\n",
    "else:\n",
    "    print(df_RE_groundtruth.head())\n",
    "\n",
    "# sort by design id ascending\n",
    "df_RE_groundtruth = df_RE_groundtruth.sort_values(by=['design_id'])\n",
    "\n",
    "\n",
    "df_RE_groundtruth.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RE_groundtruth.to_json(prep_cfg.json_path + \"/RE_groundtruth.json\", orient=\"records\")\n",
    "df_spo_triples = pd.read_json(prep_cfg.json_path + \"/subject_predicate_object_triples.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df_spo for columns\n",
    "columns = ['design_id', 's_o_id', 's', 'subject_class', 'predicate', 'o', 'object_class', \n",
    "           \"validity_pred\", \"comment_pred\", \"implicit_pred\", \"design_en\"\n",
    "           ]\n",
    "\n",
    "df_triples = df_spo_triples[columns].copy()\n",
    "df_triples = df_triples.rename(columns={\"predicate\": \"p\"})\n",
    "\n",
    "df_triples.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples.to_json(prep_cfg.json_path + \"/RE_new_datachallenge.json\", orient=\"records\")\n",
    "\n",
    "df_RE = pd.merge(df_triples, df_RE_groundtruth, on=\"design_id\", how=\"inner\")\n",
    "df_RE.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RE.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RE_compare = df_RE.rename(columns={\n",
    "    's_x': 's_new',\n",
    "    'subject_class_x': 's_class_new',\n",
    "    'p_x': 'p_new',\n",
    "    'o_x': 'o_new',\n",
    "    'object_class_x': 'o_class_new',\n",
    "    's_y': 's_old',\n",
    "    'subject_class_y': 's_class_old',\n",
    "    'p_y': 'p_old',\n",
    "    'o_y': 'o_old',\n",
    "    'object_class_y': 'o_class_old',\n",
    "    'design_en_x': 'design_en'\n",
    "})[[\n",
    "    'design_id', 's_o_id', 's_new', 's_class_new', 'p_new', 'o_new', 'o_class_new',\n",
    "    's_old', 's_class_old', 'p_old', 'o_old', 'o_class_old',\n",
    "    'design_en', 'validity_pred', 'comment_pred', 'implicit_pred'\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RE_compare.to_json(prep_cfg.json_path + \"/RE_compare_groundtruth_vs_datachallenge.json\", orient=\"records\")\n",
    "df_RE_compare.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison new triples vs Ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- create json file in (exisiting) RE formatting\n",
    "    - triples, keys and some values?\n",
    "    - map verbs/predicates to classes\n",
    "\n",
    "- Compare (some) triples with RE ground truth\n",
    "    - Read RE ground truth\n",
    "    - Check if some design_ids match\n",
    "        - if yes compare them\n",
    "        - if not, compute some\n",
    "    - create one Df merge over all matching triples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spo_triples = pd.read_json(prep_cfg.json_path + \"/subject_predicate_object_triples.json\", orient=\"records\")\n",
    "df_spo_triples.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all predicate == \"NULL\" \n",
    "\n",
    "df_spo_triples = df_spo_triples[df_spo_triples[\"predicate\"] != \"NULL\"]\n",
    "\n",
    "df_spo_triples[\"validity_pred\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 5845\n",
    "zero = 706\n",
    "minus = 390\n",
    "overall = one + zero + minus\n",
    "\n",
    "rel_one = round(one / overall, 2)\n",
    "rel_zero = round(zero / overall, 2)\n",
    "rel_minus = round(minus / overall, 2)\n",
    "\n",
    "print(f\"relative 1: {rel_one}, \\nrelative 0: {rel_zero}, \\nrelative -1: {rel_minus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_new = ['design_id', 's', 'subject_class', 'predicate', 'o', 'object_class', 'validity_pred', 'implicit_pred', 'design_en']\n",
    "df_triples_new = df_spo_triples[columns_new].copy()\n",
    "df_triples_new = df_triples_new.rename(columns={\"predicate\": \"p\"})\n",
    "df_triples_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation functions\n",
    "def agg_long(x):\n",
    "    return list(zip(x['s'], x['subject_class'], x['p'], x['o'], x['object_class'], x['validity_pred'], x['implicit_pred']))\n",
    "\n",
    "def agg_short(x):\n",
    "    return list(zip(x['s'], x['subject_class'], x['p'], x['o'], x['object_class']))\n",
    "\n",
    "# Group by 'design_id' and aggregate\n",
    "df_aggregated = df_triples_new.groupby(['design_id', 'design_en']).apply(lambda x: pd.Series({\n",
    "    'l_spo_long': agg_long(x),\n",
    "    'l_spo_short': agg_short(x)\n",
    "})).reset_index()\n",
    "\n",
    "df_aggregated.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth data from json   \n",
    "df_RE_groundtruth = pd.read_json(prep_cfg.json_path + \"/RE_groundtruth.json\", orient=\"records\")\n",
    "df_RE_groundtruth.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'design_id' and 'design_en' and aggregate\n",
    "df_aggregated_groundtruth = df_RE_groundtruth.groupby(['design_id', 'design_en']).apply(lambda x: pd.Series({\n",
    "    'l_spo_short': agg_short(x)\n",
    "})).reset_index()\n",
    "\n",
    "print(df_aggregated_groundtruth.info())\n",
    "df_aggregated_groundtruth.drop(columns=\"design_en\", inplace=True)\n",
    "df_aggregated_groundtruth.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames on 'design_id'\n",
    "df_merged = pd.merge(df_aggregated, df_aggregated_groundtruth, on='design_id', suffixes=('_new', '_gt'))\n",
    "print(df_merged.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare lists\n",
    "def compare_lists(row):\n",
    "    list_agg = row['l_spo_short_new']\n",
    "    list_gt = row['l_spo_short_gt']\n",
    "    \n",
    "    set_agg = set(list_agg)\n",
    "    set_gt = set(list_gt)\n",
    "    \n",
    "    if set_agg == set_gt:\n",
    "        return 0\n",
    "    \n",
    "    agg_dict = {(s, o): p for s, _, p, o, _ in list_agg}\n",
    "    gt_dict = {(s, o): p for s, _, p, o, _ in list_gt}\n",
    "    \n",
    "    if len(list_agg) == len(list_gt) and all((s, o) in agg_dict and agg_dict[(s, o)] != p for (s, o), p in gt_dict.items()):\n",
    "        return 0.1\n",
    "    \n",
    "    if len(list_agg) > len(list_gt) and all((s, o) in agg_dict and agg_dict[(s, o)] != p for (s, o), p in gt_dict.items()):\n",
    "        return 1.1\n",
    "    \n",
    "    if set_agg.issuperset(set_gt):\n",
    "        return 1\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.0: Exact match of l_spo_short lists in both DataFrames.\n",
    "1.0: Aggregated list contains all elements of the ground truth list plus more.\n",
    "-1.0: Aggregated list does not cover all elements of the ground truth list.\n",
    "0.1: Lists are the same length; s and o match but p values differ.\n",
    "1.1: Aggregated list is longer; s and o match but p values differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['comparison_result'] = df_merged.apply(compare_lists, axis=1)\n",
    "print(df_merged['comparison_result'].value_counts())\n",
    "print(df_merged.info())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 262\n",
    "zero = 186\n",
    "minus = 301\n",
    "overall = one + zero + minus\n",
    "\n",
    "rel_one = round(one / overall, 2)\n",
    "rel_zero = round(zero / overall, 2)\n",
    "rel_minus = round(minus / overall, 2)\n",
    "\n",
    "print(f\"rel match ++: {rel_one}, \\nrel match: {rel_zero}, \\nrel diff: {rel_minus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df_merged to json\n",
    "df_merged.to_json(prep_cfg.json_path + \"/RE_compare_groundtruth_vs_datachallenge_aggregated.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_challenge_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
