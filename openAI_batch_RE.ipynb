{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "import warnings\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Append the submodules path to the local libs directory\n",
    "repo_dir = Path().resolve()\n",
    "sys.path.append(str(repo_dir / 'libs'))\n",
    "\n",
    "# Ensure the symlink exists (assuming setup_symlink.py has been executed)\n",
    "symlink_path = repo_dir / 'libs' / 'NLP_on_multilingual_coin_datasets'\n",
    "if not symlink_path.exists():\n",
    "    print(f\"Error: Symlink {symlink_path} does not exist. Run setup_symlink.py first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Import the custom modules after ensuring symlink is in place\n",
    "from NLP_on_multilingual_coin_datasets.cnt.io import Database_Connection\n",
    "from modules.loading_preprocessed_designs import PreprocessingConfig, LoadingPreprocessedDesigns\n",
    "from modules import scripts, prompts\n",
    "\n",
    "# Set up pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Suppress warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Access the OpenAI API key from environment variables\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "prep_cfg = PreprocessingConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define filenames and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = prep_cfg.json_path\n",
    "enhanced_json_filename = \"enhanced_objects.json\"\n",
    "sop_json_filename = \"subject_object_pairs.json\"\n",
    "pred_json_filename = \"subject_predicate_object_triples.json\"\n",
    "#tmps\n",
    "tmp_dir = prep_cfg.tmp_path\n",
    "job_ids_file_name = Path(\"batch_job_ids.json\")\n",
    "job_ids_file_path = tmp_dir / job_ids_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define database connection parameters or set them as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "database = prep_cfg.database\n",
    "\n",
    "connection_string = f\"mysql+mysqlconnector://{db_user}:{db_password}@{db_host}:{db_port}/{database}\"\n",
    "dc = Database_Connection(connection_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load or preprocess data\n",
    "- Check for the preprocessed designs.csv file in the `data` directory. \n",
    "    - If it does not exist, get the data from the database and preprocess it.\n",
    "    - Else load the data from the file.\n",
    "- Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 18:46:16,603 - INFO - Checking if file data/source/lists/csv/annotated_designs.csv exists.\n",
      "2024-09-02 18:46:16,605 - INFO - File does not exist. Loading from database and running preprocessing.\n",
      "2024-09-02 18:46:16,605 - INFO - Starting preprocessing of designs.\n",
      "2024-09-02 18:46:16,864 - INFO - package: mysql.connector.plugins\n",
      "2024-09-02 18:46:16,865 - INFO - plugin_name: caching_sha2_password\n",
      "2024-09-02 18:46:16,865 - INFO - AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin\n",
      "2024-09-02 18:46:17,105 - INFO - Loaded PERSON entities successfully.\n",
      "2024-09-02 18:46:17,176 - INFO - Loaded OBJECT entities successfully.\n",
      "2024-09-02 18:46:17,244 - INFO - Loaded ANIMAL entities successfully.\n",
      "2024-09-02 18:46:17,312 - INFO - Loaded PLANT entities successfully.\n",
      "2024-09-02 18:46:29,499 - INFO - Adding rules from entities.\n",
      "Initializing Preprocess: 100%|██████████| 849/849 [00:00<00:00, 29478.18it/s]\n",
      "2024-09-02 18:46:29,557 - INFO - Completed adding rules from entities.\n",
      "2024-09-02 18:46:29,557 - INFO - Cleaning design names.\n",
      "2024-09-02 18:46:30,162 - INFO - Completed cleaning design names.\n",
      "2024-09-02 18:46:30,163 - INFO - Applying defined preprocessing rules to design names.\n",
      "2024-09-02 18:46:30,164 - ERROR - Error during preprocessing: 'DataFrame' object has no attribute 'swifter'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'swifter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wf/7y52ys5x0gb5g3hf64_5gt_m0000gn/T/ipykernel_58512/2182462503.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;31m# TODO test file creation if not exist, after adjustments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadingPreprocessedDesigns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_designs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_designs_csv_or_process_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_lokal/DataChallenge_LLM_REPipeline/modules/loading_preprocessed_designs.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mdf_designs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_designs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File exists and was loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File does not exist. Loading from database and running preprocessing.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mdf_designs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_designs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mdf_designs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_lokal/DataChallenge_LLM_REPipeline/modules/loading_preprocessed_designs.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mannotated_designs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during preprocessing: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/data_challenge_NLP/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'swifter'"
     ]
    }
   ],
   "source": [
    "# TODO test file creation if not exist, after adjustments \n",
    "lpd = LoadingPreprocessedDesigns(dc, prep_cfg)\n",
    "df_designs = lpd.load_designs_csv_or_process_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Dataframe \n",
    "\n",
    "- create copy\n",
    "- filter the columns id, design_en and annotations\n",
    "    - respresenting only the preprocessed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_designs_0 = df_designs.copy()\n",
    "df_designs = df_designs[[\"id\", \"design_en\", \"annotations\"]]\n",
    "df_designs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_designs_0.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create strings from annotations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_designs[\"list_of_strings\"] = df_designs.apply(scripts.generate_list_of_strings, axis=1)\n",
    "df_designs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a subset of the data to be used for the testing of the implementation.\n",
    "- 22332 rows\n",
    "- define top and start \n",
    "- only new ones will be processed, existing will be skipped with filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0 \n",
    "stop = 3250\n",
    "\n",
    "\n",
    "df_designs_source = df_designs.iloc[start:stop].copy()\n",
    "df_designs_source.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Check for More Possible Subjects or Objects\n",
    "- **Input:** Design description and list of strings (entities).\n",
    "- **Output:** Identified and verified subjects and objects categorized as PERSON, OBJECT, ANIMAL, PLANT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter source data for already computed datapoints.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_designs_filtered = scripts.filter_source_dataframe(df_designs_source, json_dir, enhanced_json_filename)\n",
    "df_designs_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define client and batchsize (not the OpenAI batch) but the size of the datapoints to be processed in one prompt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "batch_size = 32\n",
    "batch_start = 0 # for token calc\n",
    "batch_stop = len(df_designs_filtered)//batch_size + 1 # for token calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create prompts and batches for enhance objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** The price claculation is only an example and only for the input token, based on:\n",
    "- gpt4o, 2024-July:\n",
    "    - 5$/Million Token * 0.5 for batch API discount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_enhance = prompts.enhance_objects_in_designs(df_designs_filtered, batch_size)\n",
    "scripts.calculate_total_tokens_and_price(prompts_enhance, batch_start, batch_stop, batch=True)\n",
    "batch_file = scripts.create_tasks_batch(prompts_enhance, client, tmp_dir, step=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡¡¡ creates the batch job and sends them to the OpenAI API !!!**\n",
    "- and also saves the batch job ID to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "# Add job ID to file\n",
    "scripts.add_job_to_file(job_ids_file_path, batch_job.id, step=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the newest job ID from the file**\n",
    "- For previous job IDs check the file `temp/batch_jobs_id.json` with timestamps.\n",
    "- The idea behind this:\n",
    "    - If the kernel is restarted, the job ID is still available and the job can be continued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    newest_job_id = scripts.load_newest_job_id(job_ids_file_path, step=\"0\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the status of the job ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_info = scripts.retrieve_batch_job_status(client, newest_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the status is completed, load the results and proceed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "df_responses_enhanced = scripts.parse_and_clean_batch_responses(result)\n",
    "\n",
    "df_enhanced_merged = df_responses_enhanced.merge(\n",
    "    df_designs_filtered[['id', 'design_en', 'list_of_strings']], \n",
    "    left_on='design_id', \n",
    "    right_on='id', \n",
    "    how='left'\n",
    ").drop(columns='id')\n",
    "\n",
    "df_enhanced_merged.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0.1 Validate and Classify enhanced entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create prompts and batches for validation of enhanced objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_validate_enhanced = prompts.validate_overall_objects_in_designs(df_enhanced_merged, batch_size)\n",
    "scripts.calculate_total_tokens_and_price(prompts_validate_enhanced, batch_start, batch_stop, batch=True)\n",
    "batch_file = scripts.create_tasks_batch(prompts_validate_enhanced, client, tmp_dir, step=\"0_1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡¡¡ creates the batch job and sends them to the OpenAI API !!!**\n",
    "- and also saves the batch job ID to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "# Add job ID to file\n",
    "scripts.add_job_to_file(job_ids_file_path, batch_job.id, step=\"0_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the newest job ID from the file**\n",
    "- For previous job IDs check the file `temp/batch_jobs_id.json` with timestamps.\n",
    "- The idea behind this:\n",
    "    - If the kernel is restarted, the job ID is still available and the job can be continued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    newest_job_id = scripts.load_newest_job_id(job_ids_file_path, step=\"0_1\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the status of the job ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.retrieve_batch_job_status(client, newest_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the status is completed, load the results and proceed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "df_responses_val_enhanced = scripts.parse_and_clean_batch_responses(result)\n",
    "\n",
    "df_enhanced_validated = df_responses_val_enhanced.merge(\n",
    "    df_enhanced_merged, \n",
    "    on=['design_id'], \n",
    "    how='left')\n",
    "\n",
    "df_enhanced_validated.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save validated enahanced objects to file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['design_id', 'design_en', 'new_list_of_strings', \n",
    "           'relevance', 'correctness', 'comment_enh', 'list_of_strings']\n",
    "scripts.update_json_with_merged_df(df_enhanced_validated, columns, json_dir, enhanced_json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all different values for correctness in df_enhanced_validated\n",
    "df_enhanced_validated['correctness'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Identify Subject-Object Pairs\n",
    "- **Input:** Design description and categorized entities.\n",
    "- **Output:** List of subject-object pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced = pd.read_json(Path(json_dir) / enhanced_json_filename)\n",
    "df_enhanced.info()\n",
    "# df_enhanced['design_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enhanced_filtered = scripts.filter_enhanced_designs(df_enhanced, json_dir, sop_json_filename)\n",
    "df_enhanced_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create prompts and batches for enhance objects**\n",
    "- reduce batchsize: because!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "batch_stop = len(df_enhanced_filtered)//batch_size + 1\n",
    "prompts_sop = prompts.find_subject_object_pairs_prompts(df_enhanced_filtered, batch_size)\n",
    "scripts.calculate_total_tokens_and_price(prompts_sop, batch_start, batch_stop, batch=True)\n",
    "batch_file = scripts.create_tasks_batch(prompts_sop, client, tmp_dir, step=\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡¡¡ creates the batch job and sends them to the OpenAI API !!!**\n",
    "- and also saves the batch job ID to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "# Add job ID to file\n",
    "scripts.add_job_to_file(job_ids_file_path, batch_job.id, step=\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the newest job ID from the file**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    newest_job_id = scripts.load_newest_job_id(job_ids_file_path, step=\"1\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_info = scripts.retrieve_batch_job_status(client, newest_job_id)\n",
    "status_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "df_responses_sop = scripts.parse_and_clean_batch_responses(result)\n",
    "\n",
    "df_sop_merged = df_responses_sop.merge(\n",
    "    df_enhanced_filtered, \n",
    "    on=['design_id'], \n",
    "    how='left')\n",
    "\n",
    "df_sop_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_sop_merged to json file in tmp\n",
    "df_sop_merged.to_json(Path(tmp_dir) / \"sop_before_val_temp_save_20240701_13h52m.json\", orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the tmp saved file\n",
    "df_sop_merged = pd.read_json(Path(tmp_dir) / \"sop_before_val_temp_save_20240701_13h52m.json\")\n",
    "df_sop_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.1 Validate and Classify Object Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Batch start {batch_start}, Batch stop {batch_stop}, Batch size {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 2\n",
    "batch_size = batch_size * factor\n",
    "# batch_start = 0 \n",
    "# batch_stop = batch_stop // factor\n",
    "# print(f\"Batch start {batch_start}, Batch stop {batch_stop}, Batch size {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_validate_sop = prompts.validate_subject_object_pairs(df_sop_merged, batch_size)\n",
    "scripts.calculate_total_tokens_and_price(prompts_validate_sop, batch_start, batch_stop, batch=True)\n",
    "batch_file = scripts.create_tasks_batch(prompts_validate_sop, client, tmp_dir, step=\"1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "# Add job ID to file\n",
    "scripts.add_job_to_file(job_ids_file_path, batch_job.id, step=\"1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    newest_job_id = scripts.load_newest_job_id(job_ids_file_path, step=\"1_1\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "batch_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.batches.list())\n",
    "# list batches if status is not processed\n",
    "for batch in client.batches.list():\n",
    "    if batch.status == \"in_progress\":\n",
    "        print(batch)\n",
    "\n",
    "# client.batches.cancel(newest_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.retrieve_batch_job_status(client, newest_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "# client.files.delete(batch_job.input_file_id)\n",
    "\n",
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "df_responses_val_sop = scripts.parse_and_clean_batch_responses(result)\n",
    "\n",
    "df_sop_validated = df_responses_val_sop.merge(\n",
    "    df_sop_merged, \n",
    "    on=['design_id', 's_o_id'], \n",
    "    how='left')\n",
    "\n",
    "df_sop_validated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['design_id', 's_o_id', 's', 'subject_class', 'o', 'object_class', \n",
    "           'validity_sop', 'comment_sop', 'design_en', 'new_list_of_strings', \n",
    "           'relevance', 'correctness', 'comment_enh', 'list_of_strings'\n",
    "           ]\n",
    "scripts.update_json_with_merged_df(df_sop_validated, columns, json_dir, sop_json_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Combine Subject-Predicate-Object\n",
    "- **Input:** Design description, subject-object pairs, and possible predicates.\n",
    "- **Output:** List of subject-predicate-object triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sop = pd.read_json(Path(json_dir) / sop_json_filename)\n",
    "df_sop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count all entries in df_sop, for which validity is one value for each different value\n",
    "df_sop['validity_sop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sop_filtered = scripts.filter_sop_dataframe(df_sop, json_dir, pred_json_filename)\n",
    "df_sop_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all 'Null' values in 's' and 'o'\n",
    "df_sop_filtered = df_sop_filtered[df_sop_filtered['o'] != 'NULL']\n",
    "print(df_sop_filtered['validity_sop'].value_counts())\n",
    "df_sop_filtered.info()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "batch_stop = len(df_sop_filtered)//batch_size + 1\n",
    "prompts_pred = prompts.find_predicates_prompts(df_sop_filtered, batch_size)\n",
    "scripts.calculate_total_tokens_and_price(prompts_pred, batch_start, batch_stop, batch=True)\n",
    "batch_file = scripts.create_tasks_batch(prompts_pred, client, tmp_dir, step=\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "# Add job ID to file\n",
    "scripts.add_job_to_file(job_ids_file_path, batch_job.id, step=\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    newest_job_id = scripts.load_newest_job_id(job_ids_file_path, step=\"2\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.retrieve_batch_job_status(client, newest_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sop_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "df_responses_pred = scripts.parse_and_clean_batch_responses(result)\n",
    "\n",
    "df_pred_merged = df_responses_pred.merge(\n",
    "    df_sop_filtered, \n",
    "    on=['design_id', 's_o_id'], \n",
    "    how='left')\n",
    "\n",
    "df_pred_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Validate and Classify Extractes Relations\n",
    "- **Input:** List of subject-predicate-object triples.\n",
    "- **Output:** Validated and classified relations, marked as \"added predicates\" or \"used predicates in design\".\n",
    "\n",
    "#### Notes\n",
    "- Avoid/Filter predicates which a in the text, and a valid relation, but not in the design description.\n",
    "- Example 28/27\n",
    "    - Antoninus Pius\twearing\tWreath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_merged.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_validate_pred = prompts.validate_spo_triples(df_pred_merged, batch_size)\n",
    "scripts.calculate_total_tokens_and_price(prompts_validate_pred, batch_start, batch_stop, batch=True)\n",
    "batch_file = scripts.create_tasks_batch(prompts_validate_pred, client, tmp_dir, step=\"2_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "# Add job ID to file\n",
    "scripts.add_job_to_file(job_ids_file_path, batch_job.id, step=\"2_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    newest_job_id = scripts.load_newest_job_id(job_ids_file_path, step=\"2_1\")\n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.retrieve_batch_job_status(client, newest_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(newest_job_id)\n",
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content\n",
    "df_responses_val_pred = scripts.parse_and_clean_batch_responses(result)\n",
    "\n",
    "df_pred_validated = df_responses_val_pred.merge(\n",
    "    df_pred_merged, \n",
    "    on=['design_id', 's_o_id'], \n",
    "    how='left')\n",
    "\n",
    "df_pred_validated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['design_id', 's_o_id', 's', 'subject_class', 'predicate', 'o', 'object_class', \n",
    "           \"validity_pred\", \"comment_pred\", \"implicit_pred\", \n",
    "           'validity_sop', 'comment_sop', 'design_en', 'new_list_of_strings', \n",
    "           'relevance', 'correctness', 'comment_enh', 'list_of_strings'\n",
    "           ]\n",
    "\n",
    "scripts.update_json_with_merged_df(df_pred_validated, columns, json_dir, pred_json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_validated['validity_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_val = df_pred_validated.copy()\n",
    "df_pred_val = df_pred_val[df_pred_val['predicate'] != 'NULL']\n",
    "df_pred_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_challenge_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
